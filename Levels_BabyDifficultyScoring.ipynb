{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd0LeUTUDY0u"
      },
      "outputs": [],
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score1(text, pos, child=False):\n",
        "\n",
        "  ''' Identifies pronoun case functor '''\n",
        "  pronouns = ['she', 'her', 'herself', 'he', 'him', 'himself', 'they', 'them', 'themselves', 'we', 'us', 'ourselves', 'ourself' ]\n",
        "  returnal = False\n",
        "  words = text.split(\" \")\n",
        "  pos_list = pos.split(\" \")\n",
        "  if \"PRON\" in pos_list:\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == \"PRON\"]\n",
        "    for inx in indices:\n",
        "      if words[inx] in pronouns:\n",
        "        returnal = True\n",
        "\n",
        "  return returnal\n",
        "  #pronoun case\n",
        "  # you/it not considered as they are not influenced by case"
      ],
      "metadata": {
        "id": "I4HsY3PVDww9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score2(text, pos, child=False):\n",
        "  ''' Identifies article functor '''\n",
        "  returnal = False\n",
        "  articles = [\"a\", \"the\", \"an\"]\n",
        "  for art in articles:\n",
        "    if art in text.split(\" \"):\n",
        "      returnal = True\n",
        "  return returnal\n",
        "  #Article"
      ],
      "metadata": {
        "id": "K9LY9XCeD6kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score3(text, pos, child=False):\n",
        "  '''Identifies contractible copula '''\n",
        "  returnal = False\n",
        "  words = text.split(\" \")\n",
        "  if \"'s\" in words:\n",
        "    indices = [i for i, x in enumerate(words) if x == \"'s\"]\n",
        "    for inx in indices:\n",
        "      pos_list = pos.split(\" \")\n",
        "      if pos_list[inx] == \"VERB\":\n",
        "        returnal = True\n",
        "\n",
        "  return returnal\n",
        "  #contractible copula"
      ],
      "metadata": {
        "id": "MBVu8_lIEG3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score4(text, pos, child=False):\n",
        "  ''' Identifies progressive functor '''\n",
        "  returnal = False\n",
        "  if re.search('VERB', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'VERB']\n",
        "    for inx in indices:\n",
        "      inx_verb = text.split(\" \")[inx]\n",
        "      if inx_verb.endswith('ing'):\n",
        "        returnal = True\n",
        "\n",
        "  return returnal\n",
        "  # -ing\n",
        "  #V+ing"
      ],
      "metadata": {
        "id": "RUpIPFZoD_do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score5(text, pos, child=False):\n",
        "  ''' Identifies plural functor '''\n",
        "  returnal = False\n",
        "  avoid = ['s', 'e', 'u'] # exclude -ss (pass, mess) -es (long plural) -us (octopus, bus)\n",
        "  if re.search('NOUN', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'NOUN']\n",
        "    for inx in indices:\n",
        "      inx_noun = text.split(\" \")[inx]\n",
        "      if len(inx_noun) > 1:\n",
        "        if inx_noun.endswith('s') and inx_noun[-2] not in avoid:\n",
        "          returnal = True\n",
        "\n",
        "  return returnal\n",
        "  #plural\n",
        "  #NP+pl"
      ],
      "metadata": {
        "id": "KE9kFZQ9EElC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score6(text, pos, child=False):\n",
        "  ''' Identifies contractible auxiliary functor '''\n",
        "  returnal = False\n",
        "  if re.search('VERB VERB', pos):\n",
        "    auxes = re.findall(\"(('s)|('re)) \\w*ing\", text)\n",
        "    if len(auxes) > 0:\n",
        "      returnal = True\n",
        "\n",
        "  return returnal\n",
        "  #contractible auxiliary\n",
        "  # -be-V+ing\n",
        "  # only triggered once"
      ],
      "metadata": {
        "id": "U2HCcf8YENNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score7(text, pos, child=False):\n",
        "  ''' Identifies past regular functor '''\n",
        "  returnal = False\n",
        "  if re.search('VERB', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'VERB']\n",
        "    for inx in indices:\n",
        "      inx_verb = text.split(\" \")[inx]\n",
        "      if inx_verb.endswith('ed'):\n",
        "        returnal = True\n",
        "\n",
        "  return returnal\n",
        "  #past regular\n",
        "  #NP/Pron - (have) - V+pst - NP/Pron"
      ],
      "metadata": {
        "id": "8MpPSrcZEgXI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('irregular_verbs.txt') as infile:\n",
        "  ''' Identifies past irregular functor '''\n",
        "  irregular_verbs = infile.read().split(\"\\n\")\n",
        "\n",
        "def score8(text, pos, child=False):\n",
        "  returnal = False\n",
        "\n",
        "  if re.search('VERB', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'VERB']\n",
        "    for inx in indices:\n",
        "      inx_verb = text.split(\" \")[inx]\n",
        "      if inx_verb in irregular_verbs:\n",
        "        returnal = True\n",
        "\n",
        "  return returnal\n",
        "  #past irregular\n",
        "  #NP/pron - V+pst - NP/Pron"
      ],
      "metadata": {
        "id": "7ElJXSroEqyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score9(text, pos, child=False):\n",
        "  ''' Identifies long plural functor '''\n",
        "  returnal = False\n",
        "  if re.search('NOUN', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'NOUN']\n",
        "    for inx in indices:\n",
        "      inx_noun = text.split(\" \")[inx]\n",
        "      if inx_noun.endswith('es'):\n",
        "        returnal = True\n",
        "\n",
        "  return returnal\n",
        "  #long plural\n",
        "  #houses\n"
      ],
      "metadata": {
        "id": "c9iZx8DAExpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score10(text, pos, child=False):\n",
        "  ''' Identifies possessive functor '''\n",
        "  returnal = False\n",
        "  if re.search('NOUN', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    words = text.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'NOUN']\n",
        "    for inx in indices:\n",
        "      if inx != len(words) -1:\n",
        "        if words[inx + 1] == \"'s\":\n",
        "          if pos_list[inx + 1] != 'VERB':\n",
        "            returnal = True\n",
        "\n",
        "  return returnal\n",
        "\n",
        "  #possessive 's\n",
        "  #Det- (Adj) - N + poss-(N)"
      ],
      "metadata": {
        "id": "g-ktyS81E-DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score11(text, pos, child=False):\n",
        "  ''' Identifies third person functor '''\n",
        "  returnal = False\n",
        "  if re.search('VERB', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    words = text.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'VERB']\n",
        "    for inx in indices:\n",
        "      if words[inx].endswith(\"s\") and (score8(words[inx], 'VERB') + score7(words[inx],'VERB')) == 0 and not words[inx].endswith(\"'s\"):\n",
        "        returnal = True\n",
        "\n",
        "  return returnal\n",
        "  #3rd person singular\n",
        "  #NP/Pron+sing - V+tns - (Adv)"
      ],
      "metadata": {
        "id": "D-bB4zP5FG-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def total_score(sentence, pos_sentence, child=False):\n",
        "  '''\n",
        "  Calculates and returns total score by calling all scoring functions, SLA order\n",
        "  '''\n",
        "\n",
        "  score = 0\n",
        "\n",
        "  if score1(sentence.lower(), pos_sentence, child=child):\n",
        "    score = 1\n",
        "  if score2(sentence.lower(), pos_sentence, child=child):\n",
        "    score = 2\n",
        "  if score3(sentence.lower(), pos_sentence, child=child):\n",
        "    score = 3\n",
        "  if score4(sentence.lower(), pos_sentence, child=child):\n",
        "    score = 4\n",
        "  if score5(sentence.lower(), pos_sentence, child=child):\n",
        "    score = 5\n",
        "  if score6(sentence.lower(), pos_sentence, child=child):\n",
        "    score = 6\n",
        "  if score7(sentence.lower(), pos_sentence, child=child):\n",
        "    score = 7\n",
        "  if score8(sentence.lower(), pos_sentence, child=child):\n",
        "    score = 8\n",
        "  if score9(sentence.lower(), pos_sentence, child=child):\n",
        "    score = 9\n",
        "  if score10(sentence.lower(), pos_sentence, child=child):\n",
        "    score = 10\n",
        "  if score11(sentence.lower(), pos_sentence, child=child):\n",
        "    score = 11\n",
        "\n",
        "  return score"
      ],
      "metadata": {
        "id": "WULhhqe2Gdi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def total_score_child(sentence, pos_sentence, child=False):\n",
        "  '''\n",
        "  Calculates and returns total score by calling all scoring functions, FLA order\n",
        "  '''\n",
        "\n",
        "  score = 0\n",
        "\n",
        "  if score5(sentence.lower(), pos_sentence, child=child):  # plural\n",
        "    score = 1\n",
        "  if score9(sentence.lower(), pos_sentence, child=child):  # long plural\n",
        "    score = 1\n",
        "  if score4(sentence.lower(), pos_sentence, child=child):  # progressive\n",
        "    score = 2\n",
        "  if score7(sentence.lower(), pos_sentence, child=child):  # past regular\n",
        "    score = 3\n",
        "  if score8(sentence.lower(), pos_sentence, child=child):  # past irregular\n",
        "    score = 4\n",
        "  if score2(sentence.lower(), pos_sentence, child=child):  # article\n",
        "    score = 5\n",
        "  if score3(sentence.lower(), pos_sentence, child=child):  # contractible copula\n",
        "    score = 6\n",
        "  if score10(sentence.lower(), pos_sentence, child=child):  # possessive\n",
        "    score = 7\n",
        "  if score11(sentence.lower(), pos_sentence, child=child):  # third person\n",
        "    score = 8\n",
        "  if score6(sentence.lower(), pos_sentence, child=child):  # contractible aux\n",
        "    score = 9\n",
        "\n",
        "  return score"
      ],
      "metadata": {
        "id": "n4jcHvOImLUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def diff_score(sequence, pos, sent_tokenizer, child=False):\n",
        "  '''\n",
        "  Calculates difficulty score for a sequence given sequence, pos and sentence_tokenizer trained on full dataset\n",
        "  Returns sentence averaged difficulty score and token averaged difficulty score\n",
        "  child=True if FLA\n",
        "  '''\n",
        "\n",
        "  #sentence tokenizer\n",
        "  #chunk pos in equal lists as sentences\n",
        "  sentences = sent_tokenizer.tokenize(sequence)\n",
        "  lengths = []\n",
        "  for sent in sentences:\n",
        "    lengths.append(len(sent.split(\" \")))\n",
        "\n",
        "  splitpos = pos.split(\" \")\n",
        "  posses = []\n",
        "  start = 0\n",
        "  for i in lengths:\n",
        "    posses.append(\" \".join(splitpos[start:start + i]))\n",
        "    start = i + start\n",
        "\n",
        "  sentscores = []\n",
        "  for sent, pos in zip(sentences, posses):\n",
        "    if len(sent.split(\" \")) == len(pos.split(\" \")):\n",
        "      if child:\n",
        "        sentscores.append(total_score_child(sent,pos, child=child))\n",
        "      else:\n",
        "        sentscores.append(total_score(sent, pos, child=child))\n",
        "    else:\n",
        "      print(sent, pos)\n",
        "\n",
        "  diff = max(sentscores)\n",
        "\n",
        "  return diff"
      ],
      "metadata": {
        "id": "ATG6O7mZF0x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scoring(filepath, child=False):\n",
        "  '''\n",
        "  Takes file with sequences and scores sequences.\n",
        "  Returns dataframe with sequence, pos, sentence averaged difficulty score, token averaged difficulty score\n",
        "  child=True if FLA\n",
        "  '''\n",
        "\n",
        "  with open(filepath) as infile:\n",
        "    full = infile.read()\n",
        "\n",
        "  combined = full.split(\"\\n\")\n",
        "\n",
        "  sent_tokenizer = PunktSentenceTokenizer(full)\n",
        "\n",
        "  sequences = []\n",
        "  posses = []\n",
        "\n",
        "  for sentence in combined:\n",
        "    sent = sentence.split(\"\\t\")\n",
        "    if len(sent) > 1:\n",
        "      sequences.append(sent[0])\n",
        "      posses.append(sent[1])\n",
        "\n",
        "  diff_scores = []\n",
        "\n",
        "  for seq, pos in zip(sequences, posses):\n",
        "    if seq == \"\":\n",
        "      diff_scores.append(0)\n",
        "    else:\n",
        "      diff = diff_score(seq, pos, sent_tokenizer, child=child)\n",
        "      diff_scores.append(diff)\n",
        "\n",
        "# dictionary of lists\n",
        "  dict = {'sequence' : sequences,\n",
        "          'pos' : posses,\n",
        "          'score': diff_scores}\n",
        "\n",
        "  filepath = 'scored_sequences_levels.csv'\n",
        "  if child:\n",
        "    filepath = 'child_' + filepath\n",
        "  combined_df = pd.DataFrame(dict)\n",
        "  combined_df.to_csv(filepath)\n",
        "\n",
        "  return combined_df"
      ],
      "metadata": {
        "id": "cK2TXo-MHSpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanup(ranking):\n",
        "  \"\"\"\n",
        "  Turns tokenized sentences back into regular sentences\n",
        "  \"\"\"\n",
        "\n",
        "  cleaned_seqs = []\n",
        "  for seq in ranking['sequence']:\n",
        "    seq = re.sub(r\" ([!\\\"#\\$%&\\'\\(\\)\\*\\+,-\\./:;<=>\\?@\\[\\\\\\]\\^_`{\\|}~])\", r\"\\1\", seq)\n",
        "    seq = re.sub(r\" (n't)\", r\"\\1\", seq)\n",
        "    cleaned_seqs.append(seq)\n",
        "\n",
        "  ranking['sequence'] = cleaned_seqs\n",
        "  return ranking"
      ],
      "metadata": {
        "id": "DRVMBJqtHGts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ranking(filepath, ascending=True, child=False):\n",
        "  \"\"\"\n",
        "  Takes scored sequences, ranks them and saves ranked sequences to file.\n",
        "  score='token_score' if token averaged\n",
        "  ascending=False if reversed\n",
        "  child=True if FLA\n",
        "  \"\"\"\n",
        "\n",
        "  scoring = pd.read_csv(filepath)\n",
        "  scoring = scoring.dropna()\n",
        "\n",
        "  ranking = scoring.sort_values(by=['score'], ascending=ascending)\n",
        "  ranking = cleanup(ranking)\n",
        "\n",
        "  writefile = 'ranked_sequences_levels'\n",
        "  if not ascending:\n",
        "    writefile += \"_reversed\"\n",
        "  if child:\n",
        "    writefile += \"_child\"\n",
        "\n",
        "  writefile += \".csv\"\n",
        "  ranking.to_csv(writefile)\n",
        "  return ranking"
      ],
      "metadata": {
        "id": "4kh_yaTgF0wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_curriculum(filepath):\n",
        "  \"\"\"\n",
        "  Takes ranked sequences as input, randomly shuffles and saves to file\n",
        "  \"\"\"\n",
        "\n",
        "  scoring = pd.read_csv(filepath)\n",
        "  scoring = scoring.dropna()\n",
        "  ranking = scoring.sample(frac = 1)\n",
        "  ranking = cleanup(ranking)\n",
        "\n",
        "  writefile = 'random_curriculum.csv'\n",
        "  ranking.to_csv(writefile)\n",
        "  return ranking"
      ],
      "metadata": {
        "id": "z5DQyA0m2rMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filtered_curriculum(filepath):\n",
        "  '''\n",
        "  Takes ranked sequences and deleted any with a difficulty score of 0, saves to file\n",
        "  '''\n",
        "\n",
        "  sequences = pd.read_csv(filepath)\n",
        "  filtered = sequences.loc[sequences['sentence_score'] != 0]\n",
        "  newpath = \"filtered_\" + filepath\n",
        "  filtered.to_csv(newpath)\n",
        "\n",
        "  return filtered"
      ],
      "metadata": {
        "id": "3nKb8onlynb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scoring('clean_pred3')\n",
        "curriculum = ranking('scored_sequences_levels.csv')"
      ],
      "metadata": {
        "id": "vMoqSDVo2mMa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}