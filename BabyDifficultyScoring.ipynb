{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK2TXo-MHSpX"
      },
      "outputs": [],
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "import json\n",
        "from scoring_utils import diff_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scoring(filepath, child=False):\n",
        "  '''\n",
        "  Takes file with sequences and scores sequences.\n",
        "  Returns dataframe with sequence, pos, sentence averaged difficulty score, token averaged difficulty score\n",
        "  child=True if FLA\n",
        "  '''\n",
        "\n",
        "  with open(filepath) as infile:\n",
        "    full = infile.read()\n",
        "\n",
        "  combined = full.split(\"\\n\")\n",
        "\n",
        "  sent_tokenizer = PunktSentenceTokenizer(full)\n",
        "\n",
        "  sequences = []\n",
        "  posses = []\n",
        "\n",
        "  for sentence in combined:\n",
        "    sent = sentence.split(\"\\t\")\n",
        "    if len(sent) > 1:\n",
        "      sequences.append(sent[0])\n",
        "      posses.append(sent[1])\n",
        "\n",
        "  sent_diff_scores = []\n",
        "  tokens_diff_scores = []\n",
        "  for seq, pos in zip(sequences, posses):\n",
        "    if seq == \"\":\n",
        "      sent_diff_scores.append(0)\n",
        "      tokens_diff_scores.append(0)\n",
        "    else:\n",
        "      diff_sent, diff_tokens = diff_score(seq, pos, sent_tokenizer, child=child)\n",
        "      sent_diff_scores.append(diff_sent)\n",
        "      tokens_diff_scores.append(diff_tokens)\n",
        "\n",
        "# dictionary of lists\n",
        "  dict = {'sequence' : sequences,\n",
        "          'pos' : posses,\n",
        "          'sentence_score': sent_diff_scores,\n",
        "          'tokens_score': tokens_diff_scores}\n",
        "\n",
        "  combined_df = pd.DataFrame(dict)\n",
        "  name = 'scored_sequences'\n",
        "  if child:\n",
        "    name += 'child'\n",
        "  combined_df.to_csv(name + '.csv')\n",
        "\n",
        "  return combined_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRVMBJqtHGts"
      },
      "outputs": [],
      "source": [
        "def cleanup(ranking):\n",
        "  \"\"\"\n",
        "  Turns tokenized sentences back into regular sentences\n",
        "  \"\"\"\n",
        "\n",
        "  cleaned_seqs = []\n",
        "  for seq in ranking['sequence']:\n",
        "    seq = re.sub(r\" ([!\\\"#\\$%&\\'\\(\\)\\*\\+,-\\./:;<=>\\?@\\[\\\\\\]\\^_`{\\|}~])\", r\"\\1\", seq)\n",
        "    seq = re.sub(r\" (n't)\", r\"\\1\", seq)\n",
        "    cleaned_seqs.append(seq)\n",
        "\n",
        "  ranking['sequence'] = cleaned_seqs\n",
        "  return ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kh_yaTgF0wp"
      },
      "outputs": [],
      "source": [
        "def ranking(filepath, score='sentence_score', ascending=True, child=False):\n",
        "  \"\"\"\n",
        "  Takes scored sequences, ranks them and saves ranked sequences to file.\n",
        "  score='token_score' if token averaged\n",
        "  ascending=False if reversed\n",
        "  child=True if FLA\n",
        "  \"\"\"\n",
        "\n",
        "  scoring = pd.read_csv(filepath)\n",
        "  scoring = scoring.dropna()\n",
        "\n",
        "  ranking = scoring.sort_values(by=[score], ascending=ascending)\n",
        "  ranking = cleanup(ranking)\n",
        "\n",
        "  writefile = 'ranked_sequences'\n",
        "  if not ascending:\n",
        "    writefile += \"_reversed\"\n",
        "  if score =='tokens_score':\n",
        "    writefile += \"_token\"\n",
        "  if child:\n",
        "    writefile += \"_child\"\n",
        "\n",
        "  writefile += \".csv\"\n",
        "  ranking.to_csv(writefile)\n",
        "  return ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5DQyA0m2rMr"
      },
      "outputs": [],
      "source": [
        "def random_curriculum(filepath):\n",
        "  \"\"\"\n",
        "  Takes ranked sequences as input, randomly shuffles and saves to file\n",
        "  \"\"\"\n",
        "\n",
        "  scoring = pd.read_csv(filepath)\n",
        "  scoring = scoring.dropna()\n",
        "  ranking = scoring.sample(frac = 1)\n",
        "  ranking = cleanup(ranking)\n",
        "\n",
        "  writefile = 'random_curriculum.csv'\n",
        "  ranking.to_csv(writefile)\n",
        "  return ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def filtered_curriculum(filepath):\n",
        "  '''\n",
        "  Takes ranked sequences and deletes any with a difficulty score of 0, saves to file\n",
        "  '''\n",
        "\n",
        "  sequences = pd.read_csv(filepath)\n",
        "  filtered = sequences.loc[sequences['sentence_score'] != 0]\n",
        "  filtered.to_csv(\"filtered_ranked_sequences.csv\")\n",
        "\n",
        "  return filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pipeline\n",
        "\n",
        "\n",
        "scoring('data/prep_combined.train')\n",
        "curriculum = ranking('data/scored_sequences.csv')\n",
        "reversed = ranking('data/scored_sequences.csv', ascending=False)\n",
        "token = ranking('data/scored_sequences.csv', score='token_score')\n",
        "random = random_curriculum('data/ranked_sequences.csv')\n",
        "filtered = filtered_curriculum('data/ranked_sequences.csv')\n",
        "\n",
        "scoring('data/prep_combined.train', child=True)\n",
        "child = ranking('data/scored_sequences_child.csv', child=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
