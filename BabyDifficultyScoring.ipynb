{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKQ3AtZwPBMe",
        "outputId": "e6f801ba-4ef9-43b5-ea95-25a7fa5efb4c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/babylm/content/training/datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKCHLexSPFzV",
        "outputId": "90dbe1dc-e838-489f-d27f-7738dfef9389"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/babylm/content/training/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wd0LeUTUDY0u"
      },
      "outputs": [],
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score1(text, pos, child=False):\n",
        "\n",
        "  pronouns = ['she', 'her', 'herself', 'he', 'him', 'himself', 'they', 'them', 'themselves', 'we', 'us', 'ourselves', 'ourself' ]\n",
        "  returnal = 0\n",
        "  words = text.split(\" \")\n",
        "  pos_list = pos.split(\" \")\n",
        "  if \"PRON\" in pos_list:\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == \"PRON\"]\n",
        "    for inx in indices:\n",
        "      if words[inx] in pronouns:\n",
        "        if child:\n",
        "          returnal += 0\n",
        "        else: returnal += 1\n",
        "\n",
        "  return returnal\n",
        "  #pronoun case\n",
        "  # pron-(Aux)-(Neg)-V-(Pron)\n",
        "  # you/it not considered as they are not influenced by case"
      ],
      "metadata": {
        "id": "I4HsY3PVDww9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score2(text, pos, child=False):\n",
        "  returnal = 0\n",
        "  articles = [\"a\", \"the\", \"an\"]\n",
        "  for art in articles:\n",
        "    if art in text.split(\" \"):\n",
        "      if child:\n",
        "        returnal += 5\n",
        "      else: returnal += 2\n",
        "  return returnal\n",
        "  #Article"
      ],
      "metadata": {
        "id": "K9LY9XCeD6kJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score3(text, pos, child=False):\n",
        "  returnal = 0\n",
        "  words = text.split(\" \")\n",
        "  if \"'s\" in words:\n",
        "    indices = [i for i, x in enumerate(words) if x == \"'s\"]\n",
        "    for inx in indices:\n",
        "      pos_list = pos.split(\" \")\n",
        "      if pos_list[inx] == \"VERB\":\n",
        "        if child:\n",
        "          returnal += 6\n",
        "        else: returnal += 3\n",
        "\n",
        "  return returnal\n",
        "  #contractible copula"
      ],
      "metadata": {
        "id": "MBVu8_lIEG3M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score4(text, pos, child=False):\n",
        "  returnal = 0\n",
        "  if re.search('VERB', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'VERB']\n",
        "    for inx in indices:\n",
        "      inx_verb = text.split(\" \")[inx]\n",
        "      if inx_verb.endswith('ing'):\n",
        "        if child:\n",
        "          returnal += 2\n",
        "        else: returnal += 4\n",
        "\n",
        "  return returnal\n",
        "  # -ing\n",
        "  #V+ing"
      ],
      "metadata": {
        "id": "RUpIPFZoD_do"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score5(text, pos, child=False):\n",
        "  returnal = 0\n",
        "  avoid = ['s', 'e', 'u'] # exclude -ss (pass, mess) -es (long plural) -us (octopus, bus)\n",
        "  if re.search('NOUN', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'NOUN']\n",
        "    for inx in indices:\n",
        "      inx_noun = text.split(\" \")[inx]\n",
        "      if len(inx_noun) > 1:\n",
        "        if inx_noun.endswith('s') and inx_noun[-2] not in avoid:\n",
        "          if child:\n",
        "            returnal += 1\n",
        "          else: returnal += 5\n",
        "\n",
        "  return returnal\n",
        "  #plural\n",
        "  #NP+pl"
      ],
      "metadata": {
        "id": "KE9kFZQ9EElC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score6(text, pos, child=False):\n",
        "  if re.search('VERB VERB', pos):\n",
        "    auxes = re.findall(\"(('s)|('re)) \\w*ing\", text)\n",
        "    if child:\n",
        "      return (9*len(auxes))\n",
        "    return (6*len(auxes))\n",
        "\n",
        "  return 0\n",
        "  #contractible auxiliary\n",
        "  # -be-V+ing\n",
        "  # only triggered once"
      ],
      "metadata": {
        "id": "U2HCcf8YENNO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score7(text, pos, child=False):\n",
        "  returnal = 0\n",
        "  if re.search('VERB', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'VERB']\n",
        "    for inx in indices:\n",
        "      inx_verb = text.split(\" \")[inx]\n",
        "      if inx_verb.endswith('ed'):\n",
        "        if child:\n",
        "          returnal += 3\n",
        "        else: returnal += 7\n",
        "\n",
        "  return returnal\n",
        "  #past regular\n",
        "  #NP/Pron - (have) - V+pst - NP/Pron"
      ],
      "metadata": {
        "id": "8MpPSrcZEgXI",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9VC-rknjvmxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('irregular_verbs.txt') as infile:\n",
        "  irregular_verbs = infile.read().split(\"\\n\")\n",
        "\n",
        "def score8(text, pos, child=False):\n",
        "  returnal = 0\n",
        "\n",
        "  if re.search('VERB', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'VERB']\n",
        "    for inx in indices:\n",
        "      inx_verb = text.split(\" \")[inx]\n",
        "      if inx_verb in irregular_verbs:\n",
        "        if child:\n",
        "          returnal += 4\n",
        "        else: returnal += 8\n",
        "\n",
        "  return returnal\n",
        "  #past irregular\n",
        "  #NP/pron - V+pst - NP/Pron"
      ],
      "metadata": {
        "id": "7ElJXSroEqyM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score9(text, pos, child=False):\n",
        "  returnal = 0\n",
        "  if re.search('NOUN', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'NOUN']\n",
        "    for inx in indices:\n",
        "      inx_noun = text.split(\" \")[inx]\n",
        "      if inx_noun.endswith('es'):\n",
        "        if child:\n",
        "          returnal += 1\n",
        "        else: returnal += 9\n",
        "\n",
        "  return returnal\n",
        "  #long plural\n",
        "  #houses\n"
      ],
      "metadata": {
        "id": "c9iZx8DAExpw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score10(text, pos, child=False):\n",
        "  returnal = 0\n",
        "  if re.search('NOUN', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    words = text.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'NOUN']\n",
        "    for inx in indices:\n",
        "      if inx != len(words) -1:\n",
        "        if words[inx + 1] == \"'s\":\n",
        "          if pos_list[inx + 1] != 'VERB':\n",
        "            if child:\n",
        "              returnal += 7\n",
        "            else: returnal += 10\n",
        "\n",
        "  return returnal\n",
        "\n",
        "  #possessive 's\n",
        "  #Det- (Adj) - N + poss-(N)"
      ],
      "metadata": {
        "id": "g-ktyS81E-DJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score11(text, pos, child=False):\n",
        "  returnal = 0\n",
        "  if re.search('VERB', pos):\n",
        "    pos_list = pos.split(\" \")\n",
        "    words = text.split(\" \")\n",
        "    indices = [i for i, x in enumerate(pos_list) if x == 'VERB']\n",
        "    for inx in indices:\n",
        "      if words[inx].endswith(\"s\") and (score8(words[inx], 'VERB') + score7(words[inx],'VERB')) == 0 and not words[inx].endswith(\"'s\"):\n",
        "        if child:\n",
        "          returnal += 8\n",
        "        else: returnal += 11\n",
        "\n",
        "  return returnal\n",
        "  #3rd person singular\n",
        "  #NP/Pron+sing - V+tns - (Adv)"
      ],
      "metadata": {
        "id": "D-bB4zP5FG-5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def total_score(sentence, pos_sentence, child=False):\n",
        "  '''\n",
        "  Calculates and returns total score by calling all scoring functions\n",
        "  To be averaged over sentences or tokens\n",
        "  '''\n",
        "\n",
        "  score = 0\n",
        "\n",
        "  score += score1(sentence.lower(), pos_sentence, child=child)\n",
        "  score += score2(sentence.lower(), pos_sentence, child=child)\n",
        "  score += score3(sentence.lower(), pos_sentence, child=child)\n",
        "  score += score4(sentence.lower(), pos_sentence, child=child)\n",
        "  score += score5(sentence.lower(), pos_sentence, child=child)\n",
        "  score += score6(sentence.lower(), pos_sentence, child=child)\n",
        "  score += score7(sentence.lower(), pos_sentence, child=child)\n",
        "  score += score8(sentence.lower(), pos_sentence, child=child)\n",
        "  score += score9(sentence.lower(), pos_sentence, child=child)\n",
        "  score += score10(sentence.lower(), pos_sentence, child=child)\n",
        "  score += score11(sentence.lower(), pos_sentence, child=child)\n",
        "\n",
        "  return score"
      ],
      "metadata": {
        "id": "WULhhqe2Gdi_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity checks\n",
        "\n",
        "'''\n",
        "\n",
        "sents = [(\"Many teenagers were helping themselves .\", \"ADT NOUN VERB VERB PRON .\"), # 5 8 4 1 / 1 4 2 0\n",
        "(\"A lot of actresses ' nieces have toured that art gallery .\", \"DET NOUN PREP NOUN . NOUN VERB VERB DET NOUN NOUN .\"), #  2 9 10 9 7 / 5 1 7 1 3\n",
        "(\"It 's herself who Karen criticized .\", \"DET VERB PRON PRON NOUN VERB .\"), # 3 1 7 / 6 0 3\n",
        "(\"Rachel was apt to talk to Alicia .\", \"NOUN VERB ADJ PREP VERB PREP NOUN .\"), # 8 / 4\n",
        "(\"That adult has brought that purple octopus .\", \"DET NOUN VERB VERB DET ADJ NOUN\"), # 11 8 / 8 4\n",
        "(\"Curtis 's boss discussed four sons and Andrew discussed five sick sons .\", \"NOUN ADT NOUN VERB ADJ NOUN ADT NOUN VERB ADJ ADJ NOUN .\"), # 10 7 5 7 5 / 7 3 1 3 1\n",
        "(\"Martin did find out what every cashier that should n't drink wore .\", \"NOUN VERB VERB PREP PRON ADJ NOUN ADT VERB NEG VERB VERB .\"), # 8 8\n",
        "(\"Edward hid the cats .\", \"NOUN VERB DET NOUN .\"), #  8 2 5 / 4 5 1\n",
        "(\"What could Alan discover he has run around .\", \"PRON VERB NOUN VERB PRON VERB VERB ADV .\"), #11 1 / 8\n",
        "(\"Those turtles that are boring April could not ever break those couches .\", \"DET NOUN ADT VERB VERB NOUN VERB NEG ADV VERB DET NOUN .\"), # 4 9 9 / 2 1 1\n",
        "(\"An actor arrived at at most six lakes .\", \"DET NOUN VERB PREP PREP ADV ADJ NOUN .\"), # 7 2 9 / 5 1 3\n",
        "(\"The dress crumples .\", \"DET NOUN VERB .\")] # 2 11 / 5 8\n",
        "\n",
        "sents_scores = [18, 37, 11, 8, 19, 34, 16, 15, 12, 22, 18, 13]\n",
        "child_scores = [7, 17, 9, 4, 12, 15, 8, 10, 8, 4, 9, 13]\n",
        "\n",
        "sents = [(\"Katherine ca n't help herself .\", \"NOUN VERB ADT VERB PRON .\"), #1 / 0\n",
        "(\"Amanda 's respected by some waitresses .\", \"NOUN VERB VERB PREP ADT NOUN .\"), # 3 7 9 / 6 3 0\n",
        "(\"A lot of actresses that thought about Alice healed themselves .\", \"DET NOUN PREP NOUN ADT VERB PREP NOUN VERB PRON .\"), # 2 9 8 7 1 / 5 0 4 3 0\n",
        "(\"William has declared there to be no guests getting fired .\", \"NOUN VERB VERB PREP PREP VERB ADT NOUN VERB VERB .\"), # 7 7 4 11 5 / 3 3 2 8 1\n",
        "(\"Craig explored that grocery store .\",\"NOUN VERB ADT NOUN NOUN .\"), # 7 / 3\n",
        "(\"Brad passed one big museum and Amanda passed several .\", \"NOUN VERB ADT ADJ NOUN ADT NOUN VERB ADJ .\"), # 7 7 / 3 3\n",
        "(\"Joel discovered the vase that Patricia might take .\", \"NOUN VERB DET NOUN DET NOUN VERB VERB .\"), # 7 2 / 3 5\n",
        "(\"The forgotten newspaper article was bad .\",\"DET ADJ NOUN NOUN VERB ADJ .\"), # 8 2 / 4 5\n",
        "(\"Who has Colleen aggravated before kissing Judy ?\", \"PRON VERB NOUN VERB PREP VERB NOUN .\"), #11 7 4 / 8 3 2\n",
        "(\"Should Monica ever grin ?\", \"VERB NOUN ADT VERB .\"), # 0 / 0\n",
        "(\"There are n't many lights darkening ?\", \"PREP VERB NEG ADJ NOUN VERB .\"), # 4 5 / 2 1\n",
        "(\"A sketch of lights does n't appear .\", \"DET NOUN PREP NOUN VERB NEG VERB .\")] # 2 5 11 / 5 1 8\n",
        "\n",
        "sents_scores = [1, 19, 27, 34, 7, 14, 9, 10, 22, 0, 9, 18]\n",
        "child_scores = [0, 11, 12, 17, 3, 6, 8, 9, 13, 0, 3, 14]\n",
        "\n",
        "sents = [(\"Jeffrey 's sons are insulted by Tina 's supervisor .\", \"NOUN ADT NOUN VERB VERB PREP NOUN ADT NOUN .\"), # 10 5 7 10 / 7 1 3 7\n",
        "(\"Nancy could say every guy hides himself .\", \"NOUN VERB VERB ADJ NOUN VERB PRON .\"), # 1 11 / 0 8\n",
        "(\"There was bound to be a fish escaping .\", \"PREP VERB VERB PREP VERB DET NOUN VERB\"), # 8 8 4 2 / 4 4 2 5\n",
        "(\"Those ladies walk through those oases .\", \"DET NOUN VERB PREP DET NOUN .\"), # 9 9 / 1 1\n",
        "(\"Bruce knows that person that Dawn likes that argued about a lot of guys .\", \"NOUN VERB DET NOUN ADT NOUN VERB ADT VERB PREP DET NOUN PREP NOUN .\"), # 11 11 7 2 5 / 8 8 3 5 1\n",
        "(\"Who have many women 's touring Spain embarrassed .\", \"PRON VERB ADJ NOUN ADT VERB NOUN VERB .\"), # 10 4 7 / 7 2 3\n",
        "(\"Even these trucks have often slowed .\", \"ADV DET NOUN VERB ADV VERB .\"), # 5 7 / 1 3\n",
        "(\"Each book 's there disturbing Margaret .\", \"ADJ NOUN VERB ADT VERB NOUN .\"), # 6 4 / 9 2\n",
        "(\"This goose is n't bothering him .\", \"DET NOUN VERB NEG VERB NOUN .\")] # 11 4 / 8 2\n",
        "\n",
        "\n",
        "sents_scores = [32, 12, 22, 18, 36, 21, 12, 10, 15]\n",
        "child_scores = [18, 8, 15, 2, 25, 12, 4, 11, 10 ]\n",
        "\n",
        "for (sent, pos), score in zip(sents, child_scores):\n",
        "  calc = total_score(sent, pos, child=True)\n",
        "  if score != calc:\n",
        "    print(sent)\n",
        "    print(score)\n",
        "    print(calc)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "TM9NmuIamAsr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "963cfc4f-172c-4a2d-da42-805732940513"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nsents = [(\"Many teenagers were helping themselves .\", \"ADT NOUN VERB VERB PRON .\"), # 5 8 4 1 / 1 4 2 0\\n(\"A lot of actresses \\' nieces have toured that art gallery .\", \"DET NOUN PREP NOUN . NOUN VERB VERB DET NOUN NOUN .\"), #  2 9 10 9 7 / 5 1 7 1 3\\n(\"It \\'s herself who Karen criticized .\", \"DET VERB PRON PRON NOUN VERB .\"), # 3 1 7 / 6 0 3\\n(\"Rachel was apt to talk to Alicia .\", \"NOUN VERB ADJ PREP VERB PREP NOUN .\"), # 8 / 4\\n(\"That adult has brought that purple octopus .\", \"DET NOUN VERB VERB DET ADJ NOUN\"), # 11 8 / 8 4\\n(\"Curtis \\'s boss discussed four sons and Andrew discussed five sick sons .\", \"NOUN ADT NOUN VERB ADJ NOUN ADT NOUN VERB ADJ ADJ NOUN .\"), # 10 7 5 7 5 / 7 3 1 3 1\\n(\"Martin did find out what every cashier that should n\\'t drink wore .\", \"NOUN VERB VERB PREP PRON ADJ NOUN ADT VERB NEG VERB VERB .\"), # 8 8\\n(\"Edward hid the cats .\", \"NOUN VERB DET NOUN .\"), #  8 2 5 / 4 5 1\\n(\"What could Alan discover he has run around .\", \"PRON VERB NOUN VERB PRON VERB VERB ADV .\"), #11 1 / 8\\n(\"Those turtles that are boring April could not ever break those couches .\", \"DET NOUN ADT VERB VERB NOUN VERB NEG ADV VERB DET NOUN .\"), # 4 9 9 / 2 1 1\\n(\"An actor arrived at at most six lakes .\", \"DET NOUN VERB PREP PREP ADV ADJ NOUN .\"), # 7 2 9 / 5 1 3\\n(\"The dress crumples .\", \"DET NOUN VERB .\")] # 2 11 / 5 8\\n\\nsents_scores = [18, 37, 11, 8, 19, 34, 16, 15, 12, 22, 18, 13]\\nchild_scores = [7, 17, 9, 4, 12, 15, 8, 10, 8, 4, 9, 13]\\n\\nsents = [(\"Katherine ca n\\'t help herself .\", \"NOUN VERB ADT VERB PRON .\"), #1 / 0\\n(\"Amanda \\'s respected by some waitresses .\", \"NOUN VERB VERB PREP ADT NOUN .\"), # 3 7 9 / 6 3 0\\n(\"A lot of actresses that thought about Alice healed themselves .\", \"DET NOUN PREP NOUN ADT VERB PREP NOUN VERB PRON .\"), # 2 9 8 7 1 / 5 0 4 3 0\\n(\"William has declared there to be no guests getting fired .\", \"NOUN VERB VERB PREP PREP VERB ADT NOUN VERB VERB .\"), # 7 7 4 11 5 / 3 3 2 8 1\\n(\"Craig explored that grocery store .\",\"NOUN VERB ADT NOUN NOUN .\"), # 7 / 3\\n(\"Brad passed one big museum and Amanda passed several .\", \"NOUN VERB ADT ADJ NOUN ADT NOUN VERB ADJ .\"), # 7 7 / 3 3\\n(\"Joel discovered the vase that Patricia might take .\", \"NOUN VERB DET NOUN DET NOUN VERB VERB .\"), # 7 2 / 3 5\\n(\"The forgotten newspaper article was bad .\",\"DET ADJ NOUN NOUN VERB ADJ .\"), # 8 2 / 4 5\\n(\"Who has Colleen aggravated before kissing Judy ?\", \"PRON VERB NOUN VERB PREP VERB NOUN .\"), #11 7 4 / 8 3 2\\n(\"Should Monica ever grin ?\", \"VERB NOUN ADT VERB .\"), # 0 / 0\\n(\"There are n\\'t many lights darkening ?\", \"PREP VERB NEG ADJ NOUN VERB .\"), # 4 5 / 2 1\\n(\"A sketch of lights does n\\'t appear .\", \"DET NOUN PREP NOUN VERB NEG VERB .\")] # 2 5 11 / 5 1 8\\n\\nsents_scores = [1, 19, 27, 34, 7, 14, 9, 10, 22, 0, 9, 18]\\nchild_scores = [0, 11, 12, 17, 3, 6, 8, 9, 13, 0, 3, 14]\\n\\nsents = [(\"Jeffrey \\'s sons are insulted by Tina \\'s supervisor .\", \"NOUN ADT NOUN VERB VERB PREP NOUN ADT NOUN .\"), # 10 5 7 10 / 7 1 3 7\\n(\"Nancy could say every guy hides himself .\", \"NOUN VERB VERB ADJ NOUN VERB PRON .\"), # 1 11 / 0 8\\n(\"There was bound to be a fish escaping .\", \"PREP VERB VERB PREP VERB DET NOUN VERB\"), # 8 8 4 2 / 4 4 2 5\\n(\"Those ladies walk through those oases .\", \"DET NOUN VERB PREP DET NOUN .\"), # 9 9 / 1 1\\n(\"Bruce knows that person that Dawn likes that argued about a lot of guys .\", \"NOUN VERB DET NOUN ADT NOUN VERB ADT VERB PREP DET NOUN PREP NOUN .\"), # 11 11 7 2 5 / 8 8 3 5 1\\n(\"Who have many women \\'s touring Spain embarrassed .\", \"PRON VERB ADJ NOUN ADT VERB NOUN VERB .\"), # 10 4 7 / 7 2 3\\n(\"Even these trucks have often slowed .\", \"ADV DET NOUN VERB ADV VERB .\"), # 5 7 / 1 3\\n(\"Each book \\'s there disturbing Margaret .\", \"ADJ NOUN VERB ADT VERB NOUN .\"), # 6 4 / 9 2\\n(\"This goose is n\\'t bothering him .\", \"DET NOUN VERB NEG VERB NOUN .\")] # 11 4 / 8 2\\n\\n\\nsents_scores = [32, 12, 22, 18, 36, 21, 12, 10, 15]\\nchild_scores = [18, 8, 15, 2, 25, 12, 4, 11, 10 ]\\n\\nfor (sent, pos), score in zip(sents, child_scores):\\n  calc = total_score(sent, pos, child=True)\\n  if score != calc:\\n    print(sent)\\n    print(score)\\n    print(calc)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def diff_score(sequence, pos, sent_tokenizer, child=False):\n",
        "  '''\n",
        "  Calculates difficulty score for a sequence given sequence, pos and sentence_tokenizer trained on full dataset\n",
        "  Returns sentence averaged difficulty score and token averaged difficulty score\n",
        "  child=True if FLA\n",
        "  '''\n",
        "\n",
        "  #sentence tokenizer\n",
        "  #chunk pos in equal lists as sentences\n",
        "  sentences = sent_tokenizer.tokenize(sequence)\n",
        "  lengths = []\n",
        "  for sent in sentences:\n",
        "    lengths.append(len(sent.split(\" \")))\n",
        "\n",
        "  splitpos = pos.split(\" \")\n",
        "  posses = []\n",
        "  start = 0\n",
        "  for i in lengths:\n",
        "    posses.append(\" \".join(splitpos[start:start + i]))\n",
        "    start = i + start\n",
        "\n",
        "  total = 0\n",
        "  for sent, pos in zip(sentences, posses):\n",
        "    if len(sent.split(\" \")) == len(pos.split(\" \")):\n",
        "      total += total_score(sent, pos, child=child)\n",
        "    else:\n",
        "      print(sent, pos)\n",
        "\n",
        "  diff_sent = total / len(sentences)\n",
        "  diff_tokens = total / len(sequence.split(\" \"))\n",
        "\n",
        "  return diff_sent, diff_tokens"
      ],
      "metadata": {
        "id": "ATG6O7mZF0x_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scoring(filepath, child=False):\n",
        "  '''\n",
        "  Takes file with sequences and scores sequences.\n",
        "  Returns dataframe with sequence, pos, sentence averaged difficulty score, token averaged difficulty score\n",
        "  child=True if FLA\n",
        "  '''\n",
        "\n",
        "  with open(filepath) as infile:\n",
        "    full = infile.read()\n",
        "\n",
        "  combined = full.split(\"\\n\")\n",
        "\n",
        "  sent_tokenizer = PunktSentenceTokenizer(full)\n",
        "\n",
        "  sequences = []\n",
        "  posses = []\n",
        "\n",
        "  for sentence in combined:\n",
        "    sent = sentence.split(\"\\t\")\n",
        "    if len(sent) > 1:\n",
        "      sequences.append(sent[0])\n",
        "      posses.append(sent[1])\n",
        "\n",
        "  sent_diff_scores = []\n",
        "  tokens_diff_scores = []\n",
        "  for seq, pos in zip(sequences, posses):\n",
        "    if seq == \"\":\n",
        "      sent_diff_scores.append(0)\n",
        "      tokens_diff_scores.append(0)\n",
        "    else:\n",
        "      diff_sent, diff_tokens = diff_score(seq, pos, sent_tokenizer, child=child)\n",
        "      sent_diff_scores.append(diff_sent)\n",
        "      tokens_diff_scores.append(diff_tokens)\n",
        "\n",
        "# dictionary of lists\n",
        "  dict = {'sequence' : sequences,\n",
        "          'pos' : posses,\n",
        "          'sentence_score': sent_diff_scores,\n",
        "          'tokens_score': tokens_diff_scores}\n",
        "\n",
        "  combined_df = pd.DataFrame(dict)\n",
        "  combined_df.to_csv('scored_sequences.csv')\n",
        "\n",
        "  return combined_df"
      ],
      "metadata": {
        "id": "cK2TXo-MHSpX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanup(ranking):\n",
        "  \"\"\"\n",
        "  Turns tokenized sentences back into regular sentences\n",
        "  \"\"\"\n",
        "\n",
        "  cleaned_seqs = []\n",
        "  for seq in ranking['sequence']:\n",
        "    seq = re.sub(r\" ([!\\\"#\\$%&\\'\\(\\)\\*\\+,-\\./:;<=>\\?@\\[\\\\\\]\\^_`{\\|}~])\", r\"\\1\", seq)\n",
        "    seq = re.sub(r\" (n't)\", r\"\\1\", seq)\n",
        "    cleaned_seqs.append(seq)\n",
        "\n",
        "  ranking['sequence'] = cleaned_seqs\n",
        "  return ranking"
      ],
      "metadata": {
        "id": "DRVMBJqtHGts"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ranking(filepath, score='sentence_score', ascending=True, child=False):\n",
        "  \"\"\"\n",
        "  Takes scored sequences, ranks them and saves ranked sequences to file.\n",
        "  score='token_score' if token averaged\n",
        "  ascending=False if reversed\n",
        "  child=True if FLA\n",
        "  \"\"\"\n",
        "\n",
        "  scoring = pd.read_csv(filepath)\n",
        "  scoring = scoring.dropna()\n",
        "\n",
        "  ranking = scoring.sort_values(by=[score], ascending=ascending)\n",
        "  ranking = cleanup(ranking)\n",
        "\n",
        "  writefile = 'ranked_sequences'\n",
        "  if not ascending:\n",
        "    writefile += \"_reversed\"\n",
        "  if score =='tokens_score':\n",
        "    writefile += \"_token\"\n",
        "  if child:\n",
        "    writefile += \"_child\"\n",
        "\n",
        "  writefile += \".csv\"\n",
        "  ranking.to_csv(writefile)\n",
        "  return ranking"
      ],
      "metadata": {
        "id": "4kh_yaTgF0wp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_curriculum(filepath):\n",
        "  \"\"\"\n",
        "  Takes ranked sequences as input, randomly shuffles and saves to file\n",
        "  \"\"\"\n",
        "\n",
        "  scoring = pd.read_csv(filepath)\n",
        "  scoring = scoring.dropna()\n",
        "  ranking = scoring.sample(frac = 1)\n",
        "  ranking = cleanup(ranking)\n",
        "\n",
        "  writefile = 'random_curriculum.csv'\n",
        "  ranking.to_csv(writefile)\n",
        "  return ranking"
      ],
      "metadata": {
        "id": "z5DQyA0m2rMr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filtered_curriculum(filepath):\n",
        "  '''\n",
        "  Takes ranked sequences and deleted any with a difficulty score of 0, saves to file\n",
        "  '''\n",
        "\n",
        "  sequences = pd.read_csv(filepath)\n",
        "  filtered = sequences.loc[sequences['sentence_score'] != 0]\n",
        "  newpath = \"filtered_\" + filepath\n",
        "  filtered.to_csv(newpath)\n",
        "\n",
        "  return filtered"
      ],
      "metadata": {
        "id": "3nKb8onlynb9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # pipeline\n",
        "\n",
        "# scoring('clean_pred3')\n",
        "# curriculum = ranking('scored_sequences.csv')\n",
        "# reversed = ranking('ranked_sequences.csv', ascending=False)\n",
        "# token = ranking('ranked_sequences.csv', score='tokens_score')\n",
        "# random = random_curriculum('ranked_sequences.csv')\n",
        "# filtered = filtered_curriculum('ranked_sequences.csv')"
      ],
      "metadata": {
        "id": "CL6CirD6XZq1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # fla pipeline\n",
        "\n",
        "# scoring('clean_pred3', child=True)\n",
        "# child = ranking('scored_sequences.csv', score='tokens_score', child=True)\n",
        "# child = ranking('scored_sequences.csv', child=True)\n",
        "# filtered = filtered_curriculum('ranked_sequences_child.csv')\n",
        "# reversed = ranking('ranked_sequences_child.csv', score='tokens_score', ascending=False)"
      ],
      "metadata": {
        "id": "RlXBrmGYQqBZ"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}